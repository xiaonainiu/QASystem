{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question & Answer System\n",
    "by ES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "# import urllib\n",
    "import sys\n",
    "# import os\n",
    "# import zipfile\n",
    "# import tarfile\n",
    "import json \n",
    "# import hashlib\n",
    "import re\n",
    "# import itertools\n",
    "import gensim\n",
    "import string\n",
    "import math\n",
    "import nltk\n",
    "import random\n",
    "import csv\n",
    "import io\n",
    "import spacy\n",
    "import scipy\n",
    "from gensim.summarization import bm25\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "# from importlib import reload\n",
    "from collections import Counter\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and load files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training.json','r') as f:\n",
    "    training = json.load(f)\n",
    "\n",
    "with open('documents.json','r') as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "with open('devel.json','r') as f:\n",
    "    develop = json.load(f)\n",
    "    \n",
    "with open('testing.json','r') as f:\n",
    "    testing = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT SIMILARITY\n",
    "Use bm25 to calculate the similarity between question and each paragraph in the target document. Get the paragraph with highest score.\n",
    "For test set, return the question and paragraph.\n",
    "For training/develop set, return the index of paragraph, index of right paragraph, and right answer as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting documents dict: 441/441\r"
     ]
    }
   ],
   "source": [
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "\n",
    "def wordPreprocess(word_list):\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    word_list_preprocessed = []\n",
    "    for word in word_list:\n",
    "        word_processed = lemmatize(word.lower())\n",
    "        if word_processed not in stopWords and word_processed not in string.punctuation:\n",
    "            word_list_preprocessed.append(word_processed)\n",
    "    return word_list_preprocessed\n",
    "\n",
    "documents_dict = {}\n",
    "t = str(len(documents))\n",
    "num = 0\n",
    "for doc in documents:\n",
    "    sys.stdout.write(('getting documents dict: '+'{0}/'+t+'\\r').format(num + 1))\n",
    "    sys.stdout.flush()\n",
    "    para_list = []\n",
    "    for para in doc[\"text\"]:\n",
    "        word_list = wordPreprocess(word_tokenize(para))\n",
    "        para_list.append(word_list)\n",
    "    documents_dict[doc[\"docid\"]]=para_list\n",
    "    num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting develop data: 3097/3097\r"
     ]
    }
   ],
   "source": [
    "develop_data = []\n",
    "t = str(len(develop))\n",
    "num = 0\n",
    "for question in develop:\n",
    "    sys.stdout.write(('getting develop data: '+'{0}/'+t+'\\r').format(num + 1))\n",
    "    sys.stdout.flush()\n",
    "#     print(documents_dict[question[\"docid\"]])\n",
    "    bm25Model = bm25.BM25(documents_dict[question[\"docid\"]])\n",
    "    average_idf = sum(map(lambda k: float(bm25Model.idf[k]), bm25Model.idf.keys())) / len(bm25Model.idf.keys())\n",
    "    scores = bm25Model.get_scores(wordPreprocess(word_tokenize(question[\"question\"])),average_idf)\n",
    "    idx = scores.index(max(scores))\n",
    "    develop_data.append((question[\"question\"],documents[question[\"docid\"]][\"text\"][idx],idx,question[\"answer_paragraph\"],question[\"text\"]))\n",
    "    num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = []\n",
    "# t = str(len(testing))\n",
    "# num = 0\n",
    "# for question in testing:\n",
    "#     sys.stdout.write(('getting develop data: '+'{0}/'+t+'\\r').format(num + 1))\n",
    "#     sys.stdout.flush()\n",
    "#     bm25Model = bm25.BM25(documents_dict[question[\"docid\"]])\n",
    "#     average_idf = sum(map(lambda k: float(bm25Model.idf[k]), bm25Model.idf.keys())) / len(bm25Model.idf.keys())\n",
    "#     scores = bm25Model.get_scores(word_tokenize(question[\"question\"]),average_idf)\n",
    "#     idx = scores.index(max(scores))\n",
    "#     test_data.append((question[\"question\"],documents[question[\"docid\"]][\"text\"][idx],idx))\n",
    "#     num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function:\n",
    "print the acurate of similarity part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7859218598643849\n"
     ]
    }
   ],
   "source": [
    "def tfidfAcurate(data_list):\n",
    "    data_count = 0\n",
    "    correct_count = 0\n",
    "    for data in data_list:\n",
    "#         print(data)\n",
    "        data_count+=1\n",
    "#         print(data[2],data[3])\n",
    "        if data[2]==data[3]:\n",
    "            correct_count +=1\n",
    "    return float(correct_count)/data_count\n",
    "\n",
    "print(tfidfAcurate(develop_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getEntity(sentence):\n",
    "    ## spacy\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(sentence)\n",
    "    return doc.ents\n",
    "\n",
    "def getTextByLabel(entity,label_list):\n",
    "    answer_list = []\n",
    "    for lab in label_list:\n",
    "        for ent in entity:\n",
    "            label = ent.label_\n",
    "            if label == lab:\n",
    "                answer_list.append(ent.text)\n",
    "#     for ent in entity:\n",
    "#         label = ent.label_\n",
    "#         if label in label_list:\n",
    "#             answer_list.append(ent.text)\n",
    "    return answer_list\n",
    "\n",
    "def getAnswer(data_list):\n",
    "    t = str(len(data_list))\n",
    "    now = 0\n",
    "    answer=[]\n",
    "    id_num = 0\n",
    "    count = [0,0,[0,0,0],[0,0,0,0],0,[0,0,0,0],0]\n",
    "    useList = [0,0]\n",
    "    for data in data_list:\n",
    "        sys.stdout.write(('{0}/'+t+'\\r').format(id_num + 1))\n",
    "        sys.stdout.flush()\n",
    "        paragraph_entity = getEntity(data[1])\n",
    "        answer_list = list()\n",
    "        \n",
    "        if bool(re.search('who',data[0],re.IGNORECASE)):\n",
    "            count[0]+=1\n",
    "            answer_list = getTextByLabel(paragraph_entity,[\"PERSON\",\"NORP\",\"ORG\"])\n",
    "        elif bool(re.search('where',data[0],re.IGNORECASE)):\n",
    "            count[1]+=1\n",
    "            answer_list = getTextByLabel(paragraph_entity,[\"GPE\",\"LOC\",\"FACILITY\"])\n",
    "        elif bool(re.search('what',data[0],re.IGNORECASE)):\n",
    "            if bool(re.search('what time',data[0],re.IGNORECASE)):\n",
    "                count[2][0]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"DATE\",\"TIME\"])\n",
    "            elif bool(re.search('what year',data[0],re.IGNORECASE) or re.search('what day',data[0],re.IGNORECASE) or re.search('what date',data[0],re.IGNORECASE)):\n",
    "                count[2][1]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"DATE\"])\n",
    "            elif bool(re.search('what city',data[0],re.IGNORECASE) or re.search('what country',data[0],re.IGNORECASE)):\n",
    "                count[2][2]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"GPE\"])\n",
    "            else:\n",
    "                count[2][2]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"PRODUCT\",\"WORK_OF_ART\",\"EVENT\",\"FACILITY\",\"ORG\"])\n",
    "        elif bool(re.search('how',data[0],re.IGNORECASE)):\n",
    "            if bool(re.search('how much',data[0],re.IGNORECASE)):\n",
    "                count[3][0]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"MONEY\"])\n",
    "            if bool(re.search('how many',data[0],re.IGNORECASE)):\n",
    "                count[3][1]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"QUANTITY\",\"MONEY\",\"CARDINAL\",\"PERCENT\"])\n",
    "            if bool(re.search('how does',data[0],re.IGNORECASE) or re.search('how was',data[0],re.IGNORECASE)):\n",
    "                count[3][2]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"LAW\",\"EVENT\"])\n",
    "            else:\n",
    "                count[3][3]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"QUANTITY\",\"MONEY\",\"CARDINAL\"])\n",
    "        elif bool(re.search('when',data[0],re.IGNORECASE)):\n",
    "            count[4]+=1\n",
    "            answer_list = getTextByLabel(paragraph_entity,[\"DATE\",\"TIME\"])\n",
    "        elif bool(re.search('which',data[0],re.IGNORECASE)):\n",
    "            if bool(re.search('which person',data[0],re.IGNORECASE)):\n",
    "                count[5][0]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"PERSON\"])\n",
    "            elif bool(re.search('which time',data[0],re.IGNORECASE)):\n",
    "                count[5][1]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"DATE\",\"TIME\"])\n",
    "            elif bool(re.search('which country',data[0],re.IGNORECASE)):\n",
    "                count[5][2]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"NORP\",\"ORG\"])\n",
    "            else:\n",
    "                count[5][3]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"FACILITY\",\"PRODUCT\",\"WORK_OF_ART\",\"EVENT\",\"ORG\"])\n",
    "        else:\n",
    "            count[6]+=1\n",
    "        if len(answer_list)==0:\n",
    "            useList[1]+=1\n",
    "            try:\n",
    "                index = random.randint(0,len(paragraph_entity)-1) \n",
    "                answer.append (([str(id_num)+','+paragraph_entity[index].text.replace(\",\", \"\")],data[2]))\n",
    "            except:\n",
    "                index = random.randint(0,len(data[1])-1)\n",
    "                answer.append(([str(id_num)+','+data[1][index].replace(\",\", \"\")],data[2]))\n",
    "        else:\n",
    "            useList[0]+=1\n",
    "            index = random.randint(0,len(answer_list)-1)\n",
    "            answer.append (([str(id_num)+','+answer_list[index].replace(\",\", \"\")],data[2]))\n",
    "        id_num +=1\n",
    "    print(\"count \",count)\n",
    "    print(\"use list \",useList)\n",
    "    return answer\n",
    "\n",
    "    \n",
    "\n",
    "# for line in answer:\n",
    "#     print(line)\n",
    "# count  [2198, 279, 422, 156, 563]\n",
    "# use list  [2757, 861]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3092/3097\r"
     ]
    }
   ],
   "source": [
    "# answer = getAnswer(test_data)\n",
    "answer = getAnswer(develop_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function:\n",
    "print the acurate of answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def campare(question,answer):\n",
    "    if question[4]==str(answer[0]).strip(\"'\").split(',')[1][:-2]:\n",
    "        return True\n",
    "    else:\n",
    "        print(question[0],question[4],str(answer[0]).strip(\"'\").split(',')[1][:-2])\n",
    "        return False\n",
    "\n",
    "def answerAcurate(data_list,answer):\n",
    "    data_count = 0\n",
    "    correct_count = 0\n",
    "    results = map(campare,data_list,answer)\n",
    "    for result in results:\n",
    "        data_count+=1\n",
    "        if result:\n",
    "            correct_count +=1\n",
    "    return float(correct_count)/data_count\n",
    "\n",
    "print(answerAcurate(develop_data,answer))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Write function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Write into csv file\n",
    "def writeFile(answer):\n",
    "#     sys.stdout = io.TextIOWrapper(sys.stdout.buffer,encoding='utf8')\n",
    "    out = open('answer.csv','a',newline='')\n",
    "    csv_write =csv.writer(out,dialect='excel')\n",
    "    csv_write.writerow([\"id,answer\"])\n",
    "    answerID = 0\n",
    "    for line in answer:\n",
    "        try:\n",
    "            csv_write.writerow(line[0])\n",
    "        except:\n",
    "            print(\"line \"+str(answerID)+\" cannot write： \"+str(line[0]))\n",
    "        answerID+=1\n",
    "    out.close()\n",
    "    \n",
    "writeFile(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
