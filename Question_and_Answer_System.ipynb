{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question & Answer System\n",
    "by ES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import sys\n",
    "import json \n",
    "import re\n",
    "import gensim\n",
    "import string\n",
    "import math\n",
    "import nltk\n",
    "import random\n",
    "import csv\n",
    "import io\n",
    "import spacy\n",
    "import scipy\n",
    "import heapq\n",
    "from gensim.summarization import bm25\n",
    "from collections import Counter\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and load files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training.json','r') as f:\n",
    "    training = json.load(f)\n",
    "\n",
    "with open('documents.json','r') as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "with open('devel.json','r') as f:\n",
    "    develop = json.load(f)\n",
    "    \n",
    "with open('testing.json','r') as f:\n",
    "    testing = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT SIMILARITY\n",
    "Use bm25 to calculate the similarity between question and each paragraph in the target document. Get the paragraph with highest score.\n",
    "For test set, return the question and paragraph.\n",
    "For training/develop set, return the index of paragraph, index of right paragraph, and right answer as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting documents dict: 441/441\r"
     ]
    }
   ],
   "source": [
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "\n",
    "def wordPreprocess(word_list):\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    word_list_preprocessed = []\n",
    "    for word in word_list:\n",
    "        word_processed = lemmatize(word.lower())\n",
    "        if word_processed not in stopWords and word_processed not in string.punctuation:\n",
    "            word_list_preprocessed.append(word_processed)\n",
    "    return word_list_preprocessed\n",
    "\n",
    "documents_dict = {}\n",
    "t = str(len(documents))\n",
    "num = 0\n",
    "for doc in documents:\n",
    "    sys.stdout.write(('getting documents dict: '+'{0}/'+t+'\\r').format(num + 1))\n",
    "    sys.stdout.flush()\n",
    "    para_list = []\n",
    "    for para in doc[\"text\"]:\n",
    "        word_list = wordPreprocess(word_tokenize(para))\n",
    "        para_list.append(word_list)\n",
    "    documents_dict[doc[\"docid\"]]=para_list\n",
    "    num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting develop data: 3097/3097\r"
     ]
    }
   ],
   "source": [
    "develop_data = []\n",
    "t = str(len(develop))\n",
    "num = 0\n",
    "for question in develop:\n",
    "    sys.stdout.write(('getting develop data: '+'{0}/'+t+'\\r').format(num + 1))\n",
    "    sys.stdout.flush()\n",
    "#     print(documents_dict[question[\"docid\"]])\n",
    "    bm25Model = bm25.BM25(documents_dict[question[\"docid\"]])\n",
    "    average_idf = sum(map(lambda k: float(bm25Model.idf[k]), bm25Model.idf.keys())) / len(bm25Model.idf.keys())\n",
    "    scores = bm25Model.get_scores(wordPreprocess(word_tokenize(question[\"question\"])),average_idf)\n",
    "#     idx = scores.index(max(scores))\n",
    "    idx_list = heapq.nlargest(2, enumerate(scores), key=lambda x:x[1])\n",
    "    idx, vals = zip(*idx_list)\n",
    "#     develop_data.append((question[\"question\"],documents[question[\"docid\"]][\"text\"][idx],idx,question[\"answer_paragraph\"],question[\"text\"]))\n",
    "    develop_data.append((question[\"question\"],[documents[question[\"docid\"]][\"text\"][idx[0]],documents[question[\"docid\"]][\"text\"][idx[0]]],idx,question[\"answer_paragraph\"],question[\"text\"]))\n",
    "    num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = []\n",
    "# t = str(len(testing))\n",
    "# num = 0\n",
    "# for question in testing:\n",
    "#     sys.stdout.write(('getting develop data: '+'{0}/'+t+'\\r').format(num + 1))\n",
    "#     sys.stdout.flush()\n",
    "#     bm25Model = bm25.BM25(documents_dict[question[\"docid\"]])\n",
    "#     average_idf = sum(map(lambda k: float(bm25Model.idf[k]), bm25Model.idf.keys())) / len(bm25Model.idf.keys())\n",
    "#     scores = bm25Model.get_scores(word_tokenize(question[\"question\"]),average_idf)\n",
    "#     idx = scores.index(max(scores))\n",
    "#     test_data.append((question[\"question\"],documents[question[\"docid\"]][\"text\"][idx],idx))\n",
    "#     num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function:\n",
    "print the acurate of similarity part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8737487891507911\n"
     ]
    }
   ],
   "source": [
    "def tfidfAcurate(data_list):\n",
    "    data_count = 0\n",
    "    correct_count = 0\n",
    "    for data in data_list:\n",
    "#         print(data)\n",
    "        data_count+=1\n",
    "#         print(data[2],data[3])\n",
    "#         if data[2]==data[3]:\n",
    "        if data[2][0]==data[3] or data[2][1]==data[3]:\n",
    "            correct_count +=1\n",
    "    return float(correct_count)/data_count\n",
    "\n",
    "print(tfidfAcurate(develop_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getEntity(sentence):\n",
    "    ## spacy\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(sentence)\n",
    "    return doc.ents\n",
    "\n",
    "def getTextByLabel(entitys,label_list):\n",
    "    answer_list = []\n",
    "    for lab in label_list:\n",
    "        for ent in entity:\n",
    "            label = ent.label_\n",
    "            if label == lab:\n",
    "                answer_list.append(ent.text)\n",
    "#     for ent in entity:\n",
    "#         label = ent.label_\n",
    "#         if label in label_list:\n",
    "#             answer_list.append(ent.text)\n",
    "    return answer_list\n",
    "\n",
    "def getAnswer(data_list):\n",
    "    t = str(len(data_list))\n",
    "    now = 0\n",
    "    answer=[]\n",
    "    id_num = 0\n",
    "    count = [0,0,[0,0,0],[0,0,0,0],0,[0,0,0,0],0]\n",
    "    useList = [0,0]\n",
    "    for data in data_list:\n",
    "        sys.stdout.write(('{0}/'+t+'\\r').format(id_num + 1))\n",
    "        sys.stdout.flush()\n",
    "        paragraph_entity = [getEntity(data[1][0]),getEntity(data[1][1])]\n",
    "#         for ent in paragraph_entity:\n",
    "#             print (ent.text,ent.label_)\n",
    "        answer_list = list()\n",
    "        \n",
    "        if bool(re.search('who',data[0],re.IGNORECASE)):\n",
    "            count[0]+=1\n",
    "            answer_list = getTextByLabel(paragraph_entity,[\"PERSON\",\"NORP\",\"ORG\"])\n",
    "        elif bool(re.search('where',data[0],re.IGNORECASE)):\n",
    "            count[1]+=1\n",
    "            answer_list = getTextByLabel(paragraph_entity,[\"GPE\",\"LOC\",\"FACILITY\"])\n",
    "        elif bool(re.search('what',data[0],re.IGNORECASE)):\n",
    "            if bool(re.search('what time',data[0],re.IGNORECASE)):\n",
    "                count[2][0]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"DATE\",\"TIME\"])\n",
    "            elif bool(re.search('what year',data[0],re.IGNORECASE) or re.search('what day',data[0],re.IGNORECASE) or re.search('what date',data[0],re.IGNORECASE)):\n",
    "                count[2][1]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"DATE\"])\n",
    "            elif bool(re.search('what city',data[0],re.IGNORECASE) or re.search('what country',data[0],re.IGNORECASE)):\n",
    "                count[2][2]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"GPE\"])\n",
    "            else:\n",
    "                count[2][2]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"PRODUCT\",\"WORK_OF_ART\",\"EVENT\",\"FACILITY\",\"ORG\"])\n",
    "        elif bool(re.search('how',data[0],re.IGNORECASE)):\n",
    "            if bool(re.search('how much',data[0],re.IGNORECASE)):\n",
    "                count[3][0]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"MONEY\"])\n",
    "            if bool(re.search('how many',data[0],re.IGNORECASE)):\n",
    "                count[3][1]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"QUANTITY\",\"MONEY\",\"CARDINAL\",\"PERCENT\"])\n",
    "            if bool(re.search('how does',data[0],re.IGNORECASE) or re.search('how was',data[0],re.IGNORECASE)):\n",
    "                count[3][2]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"LAW\",\"EVENT\"])\n",
    "            else:\n",
    "                count[3][3]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"QUANTITY\",\"MONEY\",\"CARDINAL\"])\n",
    "        elif bool(re.search('when',data[0],re.IGNORECASE)):\n",
    "            count[4]+=1\n",
    "            answer_list = getTextByLabel(paragraph_entity,[\"DATE\",\"TIME\"])\n",
    "        elif bool(re.search('which',data[0],re.IGNORECASE)):\n",
    "            if bool(re.search('which person',data[0],re.IGNORECASE)):\n",
    "                count[5][0]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"PERSON\"])\n",
    "            elif bool(re.search('which time',data[0],re.IGNORECASE)):\n",
    "                count[5][1]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"DATE\",\"TIME\"])\n",
    "            elif bool(re.search('which country',data[0],re.IGNORECASE)):\n",
    "                count[5][2]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"NORP\",\"ORG\"])\n",
    "            else:\n",
    "                count[5][3]+=1\n",
    "                answer_list = getTextByLabel(paragraph_entity,[\"FACILITY\",\"PRODUCT\",\"WORK_OF_ART\",\"EVENT\",\"ORG\"])\n",
    "        else:\n",
    "            count[6]+=1\n",
    "#         print(answer_list)\n",
    "        if len(answer_list)==0:\n",
    "            useList[1]+=1\n",
    "            try:\n",
    "                index = random.randint(0,len(paragraph_entity)-1) \n",
    "                answer.append (([str(id_num)+','+paragraph_entity[index].text],data[2]))\n",
    "            except:\n",
    "                index = random.randint(0,len(data[1])-1)\n",
    "                answer.append(([str(id_num)+','+data[1][index]],data[2]))\n",
    "        else:\n",
    "            answer.append(([str(id_num)+','+answer_list[0]],data[2]))\n",
    "#             useList[0]+=1\n",
    "#             index = random.randint(0,len(answer_list)-1)\n",
    "#             answer.append (([str(id_num)+','+answer_list[index].replace(\",\", \"\")],data[2]))\n",
    "        id_num +=1\n",
    "#         print(answer)\n",
    "    print(\"count \",count)\n",
    "    print(\"use list \",useList)\n",
    "    return answer\n",
    "\n",
    "    \n",
    "\n",
    "# for line in answer:\n",
    "#     print(line)\n",
    "# count  [2198, 279, 422, 156, 563]\n",
    "# use list  [2757, 861]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/3097\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-9008c5f7a169>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# answer = getAnswer(test_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetAnswer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevelop_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-55-12ed3da74a16>\u001b[0m in \u001b[0;36mgetAnswer\u001b[1;34m(data_list)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{0}/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_num\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mparagraph_entity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetEntity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;31m#         for ent in paragraph_entity:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m#             print (ent.text,ent.label_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-55-12ed3da74a16>\u001b[0m in \u001b[0;36mgetEntity\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetEntity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m## spacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ments\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# in data dir / shortcut\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_link\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_package\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# installed as package\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_package\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model_from_link\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE051\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\data\\en_core_web_sm\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_init_py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, **overrides)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE052\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath2str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, **overrides)\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0mcomponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[1;34m(self, path, disable)\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'vocab'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[0mexclude\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vocab'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 653\u001b[1;33m         \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeserializers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[1;34m(path, readers, exclude)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(p, proc)\u001b[0m\n\u001b[0;32m    647\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'to_disk'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m             \u001b[0mdeserializers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m         \u001b[0mexclude\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'vocab'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.from_disk\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\neural\\_classes\\model.py\u001b[0m in \u001b[0;36mfrom_bytes\u001b[1;34m(self, bytes_data)\u001b[0m\n\u001b[0;32m    349\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m                         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                     \u001b[0mdest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m                     \u001b[0mcopy_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mb'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                 \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\describe.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, type)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\neural\\_classes\\hash_embed.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(W, ops)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mcopy_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# answer = getAnswer(test_data)\n",
    "answer = getAnswer(develop_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function:\n",
    "print the acurate of answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03648692282854375\n"
     ]
    }
   ],
   "source": [
    "def campare(question,answer):\n",
    "    if question[4]==str(answer[0]).strip(\"'\").split(',')[1][:-2]:\n",
    "        return True\n",
    "    else:\n",
    "        print(question[0],\"answer: \"+question[4],\"your answer: \"+str(answer[0]).strip(\"'\").split(',')[1][:-2])\n",
    "        return False\n",
    "\n",
    "def answerAcurate(data_list,answer):\n",
    "    data_count = 0\n",
    "    correct_count = 0\n",
    "    results = map(campare,data_list,answer)\n",
    "    for result in results:\n",
    "        data_count+=1\n",
    "        if result:\n",
    "            correct_count +=1\n",
    "    return float(correct_count)/data_count\n",
    "\n",
    "print(answerAcurate(develop_data,answer))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Write into csv file\n",
    "def writeFile(answer):\n",
    "#     sys.stdout = io.TextIOWrapper(sys.stdout.buffer,encoding='utf8')\n",
    "    out = open('answer.csv','a',newline='')\n",
    "    csv_write =csv.writer(out,dialect='excel')\n",
    "    csv_write.writerow([\"id,answer\"])\n",
    "    answerID = 0\n",
    "    for line in answer:\n",
    "        try:\n",
    "            csv_write.writerow(line[0])\n",
    "        except:\n",
    "            print(\"line \"+str(answerID)+\" cannot write： \"+str(line[0]))\n",
    "        answerID+=1\n",
    "    out.close()\n",
    "    \n",
    "writeFile(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
